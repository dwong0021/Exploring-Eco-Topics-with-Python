{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3b6c8474-5d15-4234-9e2b-045ec8103557",
   "metadata": {},
   "source": [
    "# Wildlife Trade Exploration with Python\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f645ad6-2dd4-4086-abb8-6124b20357dc",
   "metadata": {},
   "source": [
    "**What example of Wildlife Trade are we examining?**    \n",
    "Trade from 1975 to 2022 of all eight species of Pangolin, which became illegal for commercial purposes in early 2017 (having been uplisted to CITES Appendix I in late 2016)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1192227e-bf23-47d0-8fe2-c4b933685e62",
   "metadata": {},
   "source": [
    "**What scientific approaches are we taking?**    \n",
    "Graph-theoretic and network science approaches."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bffb78b-bbf8-4ec4-ac28-276067135cdb",
   "metadata": {},
   "source": [
    "**What outputs will we develop?**    \n",
    "Network graph data structure and visualisations of this."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "408a203f-c507-4ac6-baff-c6e6d66cca36",
   "metadata": {},
   "source": [
    "**What will our outputs tell us?**      \n",
    "Support identification of the countries most involved in the legal Pangolin trade to-date, and the main international trading partnerships."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8bf3c39-c622-45f3-badc-085864d18a01",
   "metadata": {},
   "source": [
    "**Beyond the well-known Eco impacts of Wildlife Trade, what makes this example significant?**    \n",
    "Pangolins are currently the world’s most trafficked wild mammal, despite the 2017 global commercial trade ban. In fact, many sources report that illegal Pangolin trade has actually grown post-ban, with the expansion of criminal networks.     \n",
    "    \n",
    "Tackling their illegal trade is therefore an urgent conservation priority, and being able to identify the countries who were known to be most active in the legal Pangolin trade, (the aim of this example), is likely to have some predictive power in terms of tracing the apparently thriving black market."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccd6c2c2-f5de-452a-899c-ff11434e8da7",
   "metadata": {},
   "source": [
    "---\n",
    "**Data source - Pangolin Trade**\n",
    "* Tutorial filename: `WildlifeTradeExp_DATA.csv`\n",
    "* Org: CITES (Secretariat of the Convention on International Trade in Endangered Species of Wild Fauna and Flora), a multilateral treaty to protect endangered plants and animals from the threats of international trade administered by the UN Environment Programme (UNEP).\n",
    "* Resource: CITES Trade Database, which holds the official data provided by all Parties to the Convention in their mandatory annual reports on their trade in the species listed in the Convention’s Appendices. The Database currently includes over 23 million records gathered from these reports since CITES entered into force in 1975 -> https://trade.cites.org/\n",
    "* Alternative access to Resource: CITES Wildlife TradeView (user dashboard/front-end for CITES Trade Database) -> https://tradeview.cites.org/\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cadf67c7-2d5a-4c84-b66b-3e8bcce8e1c3",
   "metadata": {
    "tags": []
   },
   "source": [
    "## A. Set-up Jupyter Notebook & Pangolin Trade data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44669c29-e133-41e0-a9d0-ae016f396e67",
   "metadata": {},
   "source": [
    "> **A0.** Import the third-party packages numpy, pandas, networkx, and the matplotlib.pyplot submodule with conventional aliases.\n",
    ">```\n",
    "import pandas as pd\n",
    "import networkx as nx\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b4530e0-03a4-4e40-b265-673363d39295",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "8ae45700-d71e-44e5-9c48-7b64d7c6ac0a",
   "metadata": {},
   "source": [
    ">**A1.** For autocompletion, or if it's not working, try running this magic command. \n",
    ">```\n",
    "%config Completer.use_jedi = False\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e45a9813-40f6-4042-9612-b1a968cb9209",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "9f95e1a9-aeaf-49df-96aa-e8a1823b1144",
   "metadata": {},
   "source": [
    ">**A2.** Read-in the Pangolin trade data `\"WildlifeTradeExp_DATA.csv\"`, and assign to `raw_data`. \n",
    ">```\n",
    "raw_data = pd.read_csv(\"WildlifeTradeExp_DATA.csv\")\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50aa16c1-649d-4c0d-ba80-7a432b5c7e7c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c9b056ba-7659-4e04-b64e-dd8770a23bbf",
   "metadata": {},
   "source": [
    ">**A3.** Make a copy of `raw_data` called `df_prep`. This will be the `DataFrame` we will prep and ultimately construct our network graph from.\n",
    ">```\n",
    "df_prep = raw_data.copy()\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65fe386c-b4dc-47ba-ba8b-4b1910d5dfa9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "90cb4670-9579-4b74-a1ca-b689f3333436",
   "metadata": {
    "tags": []
   },
   "source": [
    "---\n",
    "## B. Inspect the data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66e2c895-7989-4b73-aa34-46fd370695d5",
   "metadata": {},
   "source": [
    ">**B0.** Have a look at the prep `DataFrame`, using `head()` to display the first 5 rows.\n",
    ">```\n",
    "df_prep.head()\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e64c335b-5340-4991-82e2-15f7c24fea02",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "3a82d706-9952-47e0-8a3a-c6cc8c06f8d5",
   "metadata": {},
   "source": [
    "<font color='green'>***B0. Comments***     \n",
    "*- A pandas `DataFrame` is a 2-dimensional labeled data structure with columns of potentially different data types. They can be indexed and sliced by both integer position (from `0` to `-1`), and label.*    \n",
    "*- Each column in a `DataFrame` is a pandas `Series` data structure, a 1-dimensional array with a labeled axis.*     \n",
    "*- Not all transactions have data for every column. pandas has marked these missing entries with `NaN`, which stands for \"Not a Number\".*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "accdaa36-0f48-42b8-a7a9-1a7b53ea62f1",
   "metadata": {},
   "source": [
    ">**B1.** Find out the dimensions of `df_prep`, i.e. the number of rows and columns in the `DataFrame`.\n",
    ">```\n",
    "df_prep.shape\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96fc07d1-ac16-494b-beac-7cfc673bbde1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "6fff8ea6-e1f9-4bce-83ee-29bd91572a7a",
   "metadata": {},
   "source": [
    "<font color='green'>***B1. Interpretation***    \n",
    "*- This dataset records 1,689 transactions where Pangolin commodities were traded, which date between 1975-2022.*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57e75c1a-38ea-4897-b6b6-ea96db268dd9",
   "metadata": {},
   "source": [
    ">**B2.** See what type of data (`dtype`) pandas inferred was in each column when it originally read-in the `WildlifeTradeExp_DATA.csv`.\n",
    ">```\n",
    "df_prep.dtypes\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ebfd687-3427-4685-8688-1cb706ae4ce7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "fe2f4539-a315-4a04-ae0f-b77f90921ee5",
   "metadata": {},
   "source": [
    "<font color='green'>***B2. Comment***        \n",
    "*- The `object` `dtype` is one way that pandas stores string data.*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2029d653-f724-45cc-87ff-e00850f2ba1b",
   "metadata": {},
   "source": [
    "---\n",
    "## C. Prepare the data for exploring Illegal Wildlife Trade (IWT)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba2498f7-3011-47c8-b087-9bde72a85aa8",
   "metadata": {},
   "source": [
    "<font color ='green'>***C0. Context***   \n",
    "*- The original data request from CITES deliberately did not filter trade based on any recorded purposes. Let's review CITES \"Purpose codes\" (as per the database documentation https://trade.cites.org/cites_trade_guidelines/en-CITES_Trade_Database_Guide.pdf):*\n",
    "\n",
    "**CITES Trade Database Guide - Annex 3. Purpose and source codes**    \n",
    "* B Breeding in captivity or artificial propagation\n",
    "* E Educational\n",
    "* G Botanical garden\n",
    "* H Hunting trophy\n",
    "* L Law enforcement/judicial/forensic\n",
    "* M Medical (including biomedical research)\n",
    "* N Reintroduction or introduction into the wild\n",
    "* P Personal\n",
    "* Q Circus or travelling exhibition\n",
    "* S Scientific\n",
    "* T Commercial\n",
    "* Z Zoo"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2cf9709-f854-494a-85a8-21ed947bbead",
   "metadata": {
    "tags": []
   },
   "source": [
    ">**C0.** Access the subset of `df_prep` containing just the transactions driven by the types of demand that could be more likely to persist after a ban, i.e. for `Hunting trophy`, `Personal`, `Circus or travelling exhibition`, or `Commercial` purposes, as well as where this data is missing. Reassign `df_prep` to point to the copied subset.    \n",
    ">\n",
    "> **Code Detail:** Use Boolean masking/indexing to return the dataframe with just the rows with the `\"Purpose\"` column value of either `\"H\"`, `\"P\"`, `\"Q\"`, `\"T\"`, or `np.nan`. \n",
    ">```\n",
    "df_prep = df_prep[df_prep[\"Purpose\"].isin([\"H\", \"P\", \"Q\", \"T\", np.nan])].copy()\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19338a38-467e-4278-9f08-78adc1677c79",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "809cf414-5620-4b28-967b-4cd744079536",
   "metadata": {},
   "source": [
    ">**C1.** Check that `df_prep` has fewer rows than before.\n",
    ">```\n",
    "df_prep.shape\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d12de038-2430-4d72-b254-513eee54d890",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "9dd0c3a1-75f5-4acf-be25-aef44f99ab9c",
   "metadata": {},
   "source": [
    ">**C2.** We need to be able to quantitatively compare transactions in the dataset in terms of the volume of wild Pangolin specimens lost.     \n",
    "Compute a quick histogram/frequency table of the `\"Term\"` column values, to see the different Pangolin commodities traded.\n",
    ">```\n",
    "df_prep[\"Term\"].value_counts(dropna=False)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe00c7d1-ed71-4254-bc47-b013a3d39b42",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "0a4637a4-aa75-4ba8-b9d6-d1a89baf9e8e",
   "metadata": {},
   "source": [
    ">**C3.** As a necessary but imperfect approach to standardising the trades, subset `df_prep` for the transactions involving commodities where each unit is more likely to represent one Pangolin animal taken from the wild (rather than a constituent part), i.e. `skins`, `live`, `bodies`, `trophies`, and `specimens`. Be aware our remaining data will significantly undercount relevant traded Pangolin numbers.\n",
    ">\n",
    ">**Code Detail:** Perform Boolean masking/indexing again to return the dataframe with just the rows where the element in the `\"Term\"` columns is one of the relevant string values. Reassign `df_prep` to point to the copied subset.\n",
    "```\n",
    "df_prep = df_prep[df_prep[\"Term\"].isin([\"skins\", \"live\", \"bodies\", \"trophies\", \"specimens\"])].copy()\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "285c73c7-c73c-4694-8ec5-64ce1ea111f0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "98bc8b83-dbbc-4756-9e20-486f67b34a23",
   "metadata": {},
   "source": [
    ">**C4.** Check that `df_prep` now has even fewer rows than before.\n",
    ">```\n",
    "df_prep.shape\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6a4fb62-48d6-4e02-978a-706adf275992",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "954e782f-5329-4c81-af00-9dd7023925da",
   "metadata": {},
   "source": [
    "<font color='green'>***C4. Comment***     \n",
    "*- We have cut the number of Pangolin transactions in our dataset from 1,689 originally, to 1,396 to now 612.*       \n",
    "*- Whilst the steps taken in this section to clean the original dataset have undoubtedly dropped relevant data as well as retained less relevant data, these remaining 612 trade records are still a useful subset for demonstrating a Python-enabled graph-theoretic approach, and being able to derive limited, but interpretable outputs related to real-world IWT.*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c99a310f-cc5a-4b53-b81f-4432c3593169",
   "metadata": {},
   "source": [
    "---\n",
    "## D. Prepare the data for network graph construction "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13b54b0b-ce3b-43a1-a217-2a2e03640898",
   "metadata": {},
   "source": [
    "<font color=\"green\">***D0. Intro***     \n",
    "*- As previewed, we are preparing to turn our Pangolin trade data into a network graph where the nodes (vertices) represent the countries importing and exporting Pangolin commodities, and the edges connecting them represent trade from an exporting country to an importing country.*    \n",
    "*- There are multiple graph types. We will construct a `MultiDiGraph`, a directed graph with self loops and parallel edges. See networkx docs -> https://networkx.org/documentation/stable/reference/classes/index.html*    \n",
    "*- For each directed edge we designate the country who exported (sold) the goods as the `source node`, and the country who imported (bought) the goods as the `target node`. Arrows are drawn from the source node to the target node.*    \n",
    "*- Parallel edges of our `MultiDiGraph` will reflect a pair of countries who have made Pangolin trades where one was the buyer and the other the seller, and vice versa.*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d055722-4d36-4e26-a376-18d5b1273b36",
   "metadata": {},
   "source": [
    ">**D0.** We can only construct a Pangolin trade graph data structure from transactions with both defined `source nodes` and `target nodes`. Our visualisation also requires quantity data for each transaction, which we'll address after. First check if any `NaN` values exist in either the `\"Importer\"` or `\"Exporter\"` columns.    \n",
    ">\n",
    ">**Code Detail:** Index the dataframe by passing a list of column labels. The expression evaluates to a Boolean value.\n",
    ">```\n",
    "df_prep[[\"Importer\", \"Exporter\"]].isna().values.any()\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9e63e6a-4b5e-4f1b-a168-ba4f96f63208",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "491eaf14-e715-40c9-bd89-0e5594ffe662",
   "metadata": {},
   "source": [
    ">**D1.** (OPTIONAL) We can double-check **D0.** with an alternative operation, namely Boolean masking that combines two conditional statements with the or operator `|`.\n",
    ">```\n",
    "df_prep[ (df_prep[\"Importer\"] == np.nan) | (df_prep[\"Exporter\"] == np.nan) ]\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de3b4103-d00b-413e-b83d-bb9cdbf63ed3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "04a33a7b-f8f4-4667-ad73-bce63eb69abb",
   "metadata": {
    "tags": []
   },
   "source": [
    ">**D2.** Now turning to the availability of quantity data for each transaction, try randomly sampling rows of the dataset, say 10 at a time, maybe a few times.\n",
    ">```\n",
    "df_prep.sample(10)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e420ce23-c56c-4dae-9658-ec1ddc86b3b0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "009663d5-181d-409f-9a6c-9348741d333f",
   "metadata": {},
   "source": [
    ">**D3.** Find any transactions/rows which are missing both `\"Importer reported quantity\"` and `\"Exporter reported quantity\"` data.\n",
    ">\n",
    ">**Code Detail:** Another Boolean masking operation, this time combining two conditional statements with the and operator `&`.\n",
    ">```\n",
    "df_prep [ (df_prep[\"Importer reported quantity\"] == np.nan) & (df_prep[\"Exporter reported quantity\"] == np.nan)]\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d59cedd9-f71b-4d3b-8f9a-73138e909d24",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ab963869-be7c-4e1c-bb1f-686a19158bc8",
   "metadata": {},
   "source": [
    ">**D4.** Construct new quantity data for every transation, where the value is the greater of the reported quantities, or the only reported quantity.\n",
    ">\n",
    ">**Code Detail:** Extend the dataframe by assigning a new index value `\"quantity\"` using the indexing operator. `np.nanmax()` here returns the maximum quantity, ignoring any `NaN`s. The `apply()` function's `axis` parameter determines whether the supplied function is applied to each column (default), or each row (pass `1` or `columns` as a keyworded argument).\n",
    ">```\n",
    "df_prep[\"quantity\"] = df_prep.apply(lambda x: np.nanmax( x[[\"Importer reported quantity\", \"Exporter reported quantity\"]] ), axis=\"columns\")\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcd8ca76-2586-469a-9fff-e4e4faa9dbf8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "5254359d-5f4e-42fc-aa60-00c8ce20075c",
   "metadata": {},
   "source": [
    ">**D5.** Review the new `\"quantity\"` column.\n",
    ">```\n",
    "df_prep.head()\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da00c5a1-bb9f-440e-b87b-562ad20da543",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c076540c-8433-417c-a69a-c0a9b78c88ad",
   "metadata": {
    "tags": []
   },
   "source": [
    "---\n",
    "## E. Construct edge lists"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f44658b9-e65b-4760-a21f-f5636b67e9f1",
   "metadata": {},
   "source": [
    "<font color=\"green\">***E. Intro***         \n",
    "*- An edge list is a data structure used to represent a network graph, and is a listing of adjacent nodes.*     \n",
    "*- Our edge list will differentiate between `source` and `target` nodes, a necessary distinction for directed graphs.*    \n",
    "*- We will also include the new `\"quantity\"` data for each edge in our edge list. This edge attribute will be used as weights.*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "962f0f3e-96f8-44c4-a37e-315db277f139",
   "metadata": {
    "tags": []
   },
   "source": [
    ">**E0.** Construct an initial edge list called `edgelist_raw` by copying the subset of `df_prep` with just the `\"Importer\"`, `\"Exporter\"`, and `\"quantity\"` columns.\n",
    ">```\n",
    "edgelist_raw = df_prep[ [\"Importer\", \"Exporter\", \"quantity\"]  ].copy()\n",
    "edgelist_raw\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d50aefda-edd3-4dea-8e96-4a79b51108a3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "013180ec-2f7c-44f5-96c4-0830675e4253",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "432b7055-2306-4031-9fa9-c6bd9b3d969a",
   "metadata": {
    "tags": []
   },
   "source": [
    "<font color=\"green\">***E1. Context***     \n",
    "*- Whilst we could construct and draw a `MultiDiGraph` from `edgelist_raw` as-is, the visualisation would obscure significant edge detail.*    \n",
    "*- Repeated directed edges between a pair of nodes, such as the 2 transactions from the Netherlands to Great Britain, when both drawn with the same default line in the same position, would look indistinguishable from a single default line representing a single directed edge. Even if the line widths could be drawn with varying widths, in the case of multiple edges only the widest line would be visible, dwarfing thinner lines.*      \n",
    "*_ We will therefore create another edge list with just the unique pairs of `source` & `target` nodes, i.e. particular exporter and importer, with an aggregate quantity metric, namely the totals of the quantities recorded in all the trades made between each particular exporter and importer.*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec018e90-f5a2-4742-a62d-5db687ccba4b",
   "metadata": {},
   "source": [
    ">**E1.** Create `edgelist_unique`, a `DataFrame` produced by performing a `groupby()` operation on `edgelist_raw` which groups rows by unique `\"Exporter\"` and `\"Importer\"` combo, sums the row `\"quantity\"` values within each group, and also renames the `\"quantity\"` column as `\"weight\"`.    \n",
    ">\n",
    ">**Tech Note:** Learn more about `groupby()` split-apply-combine -> https://pandas.pydata.org/pandas-docs/stable/user_guide/groupby.html#group-by-split-apply-combine\n",
    ">```\n",
    "edgelist_unique = edgelist_raw.groupby([\"Exporter\", \"Importer\"], as_index=False).sum().sort_values(\"quantity\", ascending=False).rename(columns={\"quantity\": \"weight\"})\n",
    "edgelist_unique\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96b55c6d-cf41-40f5-b61d-0fffac32de72",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ca6f997-16e6-4d81-9c70-9749436d3915",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "6c22aafe-7f2f-4272-a53b-7f1f1bdc3995",
   "metadata": {},
   "source": [
    "<font color=\"green\">***E1. Comment***    \n",
    "*- The row dimension of this resulting edge list tells us that there are 138 unique Pangolin trading relationships in this network.*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab2d45c4-5ec3-44bd-9dea-131fa8154626",
   "metadata": {},
   "source": [
    ">**E2.** (OPTIONAL) Sum the `\"weight\"` column to get a sense of how many wild Pangolins numbers could be represented in our trade network.\n",
    ">```\n",
    "edgelist_unique.weight.sum()\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b336bef-9c4a-4b88-8e07-c5991ec5ace1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "7d53affd-7349-4ac2-8b0b-72e6bdc61c76",
   "metadata": {},
   "source": [
    "---\n",
    "## F. Construct & draw MultiDiGraph"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "546c0f7d-ad1e-4e34-9ef7-1b25d1570c00",
   "metadata": {},
   "source": [
    "<font color=\"green\">***F. Intro***     \n",
    "*- From this point onwards we start to use matplotlib in the Tutorial.*     \n",
    "*- Be aware that there are a variety of styles (APIs) available for accessing matplotlib functionality, and this is reflected in the Tutorial.*    \n",
    "*- Official matplotlib cheatsheets are available -> https://matplotlib.org/cheatsheets/*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "002ad9eb-1e99-4ab4-8bf7-f61b179fb6e0",
   "metadata": {},
   "source": [
    ">**F0.** Create a `MultiDiGraph` object using the networkx function `from_pandas_edgelist()`. Pass in required inputs from the `edgelist_unique` `DataFrame`, as well as optionally specifying the `\"weight\"` column data as an attribute of the edges, and the graph type to be `MultiDiGraph`. Assign to the variable `G`.\n",
    ">\n",
    ">**Tech Note:** Attributes such as weights, labels, colors can be attached to graphs, nodes, or edges. Each graph, node, and edge can hold key/value attribute pairs in an associated attribute dictionary -> https://networkx.org/documentation/stable/tutorial.html#adding-attributes-to-graphs-nodes-and-edges\n",
    ">```\n",
    "G = nx.from_pandas_edgelist(df=edgelist_unique, source=\"Exporter\", target=\"Importer\", edge_attr=\"weight\", create_using=nx.MultiDiGraph())\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46bf014d-19ce-4df9-ab46-5b6fcdef92cc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e32a9806-3d1b-4cd5-8861-3856c9a9919f",
   "metadata": {},
   "source": [
    ">**F1.** Use networkx's basic matplotlib drawing functionality to try a minimal visualisation of our Pangolin trade network `G`.\n",
    ">\n",
    ">**Tech Note:** Node positions can be manually provided or calculated by a node positioning algorithm every execution. You can use the `seed` parameter of networkx layout functions to control reproducibility. The optional `pos` argument passed here generates a layout of the nodes using the Fruchterman-Reingold force-directed algorithm with `k` setting the optimal distance between nodes (higher values move nodes farther apart).\n",
    ">```\n",
    "nx.draw_networkx(G, pos=nx.spring_layout(G, k=20))    \n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e44429f-08b7-4442-99c9-2d70255e44e8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "69626345-bb20-4e58-a9be-acf6854b0423",
   "metadata": {},
   "source": [
    "---\n",
    "## G. Draw customised MultiDiGraph"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dabe35e3-73ea-4fd0-beb4-2239b8a1e0b7",
   "metadata": {},
   "source": [
    "<font color=\"green\">***G. Intro***    \n",
    "*- FYI networkx is not a plotting library!! As per the docs, *\"In the future, graph visualization functionality may be removed from NetworkX or only available as an add-on package\", and they \"highly recommend that people visualize their graphs with tools dedicated to that task\"* -> https://networkx.org/documentation/stable/reference/drawing.html#drawing*    \n",
    "*- Because constructing matplotlib-drawn networkx graphs has low transferability, we use this section to demonstrate ideas for fine-tuning network visualisations, not recommending specific implementations.*    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ff152f4-11ce-462c-8d1e-60e5aac150e0",
   "metadata": {},
   "source": [
    ">**G0.** Prepare the 2 numpy arrays, `scaled_drawing_values` and `custom_edge_colors`, that will be used to draw the edges of our `MultiDigraph` with varying widths and colours proportional to their weight (i.e. quantity).  \n",
    ">\n",
    ">```\n",
    "list_drawing_values = []\n",
    "for i in G.edges(data=True):\n",
    "    list_drawing_values.append( i[2][\"weight\"] )\n",
    ">\n",
    ">scaled_drawing_values = np.digitize(list_drawing_values, bins=np.arange(0, 320000, 40000))\n",
    ">\n",
    ">cmap = plt.colormaps[\"RdYlGn_r\"]\n",
    "norm_class = plt.Normalize(vmin=min(scaled_drawing_values), vmax=max(scaled_drawing_values))    # Actual values are vmin=1, vmax=8\n",
    "custom_edge_colors = cmap(norm_class(scaled_drawing_values))\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f09fbf0a-a63b-49df-b657-cd2a9327c6ba",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a7990def-455a-4719-9d26-a64d5a00c9d4",
   "metadata": {},
   "source": [
    ">**G1.** Draw a customised matplotlib visualisation of our Pangolin trade network with a plotting routine that exploits more of the available options, i.e. function to draw just nodes, just node labels etc.\n",
    ">\n",
    ">**Code Detail:** Note that we are using `named colors` recognised by matplotlib as keyworded arguments to override the defaults (as per F1. blue for `node_color`, black for the `font_color`). See docs for full options -> https://matplotlib.org/stable/gallery/color/named_colors.html\n",
    ">\n",
    ">**Tech Note:** An alternative/popular layout is the `kamada_kawai_layout()`, but requires the scipy package. \n",
    ">```\n",
    "plt.figure(figsize=(12,12))    # Create an empty matplotlib Figure - use the figsize parameter to control the (<width>, <height>), apparently in inch units\n",
    "pos = nx.spring_layout(G, k=40, seed=7)    # Pass any integer as the `seed` argument    \n",
    "nx.draw_networkx_nodes(G, pos, node_color=\"black\", node_size=1000)\n",
    "nx.draw_networkx_labels(G, pos, font_color=\"white\", font_size=18)\n",
    "nx.draw_networkx_edges(G, pos, width=scaled_drawing_values, edge_color=custom_edge_colors, arrows=True, arrowsize=12, min_target_margin=20)\n",
    "plt.axis(\"off\")\n",
    "#plt.tight_layout()\n",
    "#plt.savefig(\"<SomeFilename>.png\", dpi=600)    # Save the Figure/Axes using matplotlib - use the optional dpi (dots-per-inch) argument to control the resolution of the png\n",
    "plt.show()    # Display the plot\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3598de5-6910-4291-a940-356548894f83",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "349e5f31-a53a-4f52-8652-e203a5b58917",
   "metadata": {},
   "source": [
    "<font color=\"green\">***G1. Comments***        \n",
    "*- A few of the further caveats/considerations re. drawing inferences from our Pangolin trade network graph include possible range in the quality of trade monitoring and record-keeping by country, as well as influential geopolitical factors, for example not all countries are Parties to the Convention, or have been at all times, plus there were changes to country boundaries/existence between 1975 to 2022.*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9538f09e-fe68-4d68-80a7-a137bc7be93a",
   "metadata": {},
   "source": [
    "---\n",
    "## H. Beyond visualising networks graphs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fbf2c78-b1ef-42e1-981c-61c678f96449",
   "metadata": {},
   "source": [
    "<font color=\"green\">***H. Intro***    \n",
    "*- Visualising the Pangolin trade network is already helpful, but is really just the beginning, not the end, of what's possible in terms of exploring Wildlife Trade with Python.*    \n",
    "*- Natural next steps would be networkx's Centrality Measures, and Community Detection algorithms. However, let's end this Exploration with a quick look at Degree Centrality, where a node's degree is the number of connections it has. This is the simplest approach to identifying important nodes.*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d77cfb32-7891-4383-8eb7-66321e0e2e66",
   "metadata": {},
   "source": [
    ">**H0.** Although we could have calculated this at earlier stages/other points, let's use our network graph's method `number_of_nodes()` to return how many nodes, and therefore unique countries, are in our network.\n",
    ">```\n",
    "G.number_of_nodes()\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "537b8e61-4b94-4cae-aac8-354aeb3a3455",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "eb92f3c2-1c12-42cc-a604-da241d027091",
   "metadata": {},
   "source": [
    ">**H1.** Whilst our network visualisation shows (within the confines of our custom framework) the important nodes/countries involved in the Pangolin trade by eye, we can refer to actual metrics too. Use networkx centrality functionality to compute the degree centrality for all nodes in our graph `G`. The degree centrality for a node is the fraction of nodes it is connected to, and represents an importance score. \n",
    ">\n",
    ">**Tech Note:** See networkx example -> https://networkx.org/nx-guides/content/exploratory_notebooks/facebook_notebook.html#degree-centrality\n",
    ">```\n",
    "nx.centrality.degree_centrality(G)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "133f2855-2b35-4aa4-8ec4-0c62c3d2b0b7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "eb3ffb93-95b3-4545-be1f-a6730d0bad6a",
   "metadata": {
    "tags": []
   },
   "source": [
    ">**H2.** Let's sort the above dictionary result by highest to lowest degree centrality, and select just the top 10 elements/countries.\n",
    ">```\n",
    "sorted(nx.centrality.degree_centrality(G).items(), key=lambda item: item[1], reverse=True)[:10]\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02ef6a60-d684-4138-b56f-9cd16ea92216",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "57cadc7e-33ea-4dd9-9ca9-5746883878d9",
   "metadata": {},
   "source": [
    "<font color=\"green\">***H2. Comment***    \n",
    "*- The values can be interpreted as the US has the highest degree centrality with 0.907, meaning it's the country (within our specific analysis) that has traded in Pangolins with the most other countries, i.e. ~91% of the 55 countries in this network (equating to 49 countries, according to `G.degree[\"US\"]`).*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76466159-6381-4a7f-bca9-6803fae4b9eb",
   "metadata": {},
   "source": [
    "---\n",
    "Copyright © 2023 Rho Zeta AI Ltd. All rights reserved."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "nteract": {
   "version": "0.28.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
